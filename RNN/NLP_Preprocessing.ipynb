{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyN1FYzZKdEeWAdrHIVUMjXQ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Tokenization (English)"],"metadata":{"id":"D3XR0TJ-bhnj"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jgs362-ebZGT","executionInfo":{"status":"ok","timestamp":1701757691084,"user_tz":-480,"elapsed":2982,"user":{"displayName":"黃茂勛","userId":"15068294769745416772"}},"outputId":"469c0f43-207a-4db8-c144-55e938557843"},"outputs":[{"output_type":"stream","name":"stdout","text":["英文斷詞： ['i', 'love', 'jogging', 'and', 'you']\n"]}],"source":["# 英文斷詞\n","from tensorflow.keras.preprocessing.text import text_to_word_sequence\n","print(\"英文斷詞：\", text_to_word_sequence(\"I love jogging, and you?\"))"]},{"cell_type":"markdown","source":["# Tokenization (Chinese)"],"metadata":{"id":"u1a5kJWVeGrV"}},{"cell_type":"code","source":["# Jieba\n","# Spacy (工業級, 使用BERT為基礎)\n","\n","# Install jieba（結巴）\n","!pip install jieba\n","\n","# Get the Tokenization Dictionary for Traditional Chinese\n","import os\n","Dictionary_File = 'dict.txt.big'\n","\n","if not os.path.isfile(Dictionary_File):\n","    os.system('wget https://raw.githubusercontent.com/cnchi/datasets/master/' + Dictionary_File)\n","\n","# Get the Stop Words File for Traditional Chinese\n","# 了, 吧, 啦, etc.\n","StopWords_File = \"stopWords_big5.txt\"\n","\n","if not os.path.isfile(StopWords_File):\n","    os.system('wget https://raw.githubusercontent.com/cnchi/datasets/master/' + StopWords_File)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"959bQujGeGI0","executionInfo":{"status":"ok","timestamp":1701757699196,"user_tz":-480,"elapsed":8114,"user":{"displayName":"黃茂勛","userId":"15068294769745416772"}},"outputId":"01d56112-285d-4243-9a76-e1d3c3797e97"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: jieba in /usr/local/lib/python3.10/dist-packages (0.42.1)\n"]}]},{"cell_type":"code","source":["import jieba\n","\n","# Set Dictionary for Traditional Chinese\n","# jieba.set_dictionary(Dictionary_File)\n","\n","# Tokenization\n","result = list(jieba.cut(\"我喜歡跑步，你呢？\"))\n","print(\"中文斷詞（有標點）：\", result)\n","\n","# Remove Stop Words from Set\n","stopWords = set(\"$!&#%\\()+-*/_,. 　?:;'\\\"<=>^`|~[]{}’0123456789?_“”、。《》！，：；？「」（）\")\n","print(\"中文斷詞（無標點）：\", [word for word in result if word not in stopWords])\n","\n","# Remove Stop Words from Files\n","stopWords = set()\n","with open(StopWords_File, \"rt\", encoding=\"utf-8\") as f:\n","  for line in f:\n","    line = line.strip() # Remove trailing \\n\n","    stopWords.add(line)\n","print(\"中文斷詞（更精簡）：\", [word for word in result if word not in stopWords])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CfV61ID3eEvx","executionInfo":{"status":"ok","timestamp":1701757699734,"user_tz":-480,"elapsed":542,"user":{"displayName":"黃茂勛","userId":"15068294769745416772"}},"outputId":"8f760fa8-3459-4f62-ea07-3f33c2b1d29d"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["Building prefix dict from the default dictionary ...\n","DEBUG:jieba:Building prefix dict from the default dictionary ...\n","Dumping model to file cache /tmp/jieba.cache\n","DEBUG:jieba:Dumping model to file cache /tmp/jieba.cache\n","Loading model cost 0.746 seconds.\n","DEBUG:jieba:Loading model cost 0.746 seconds.\n","Prefix dict has been built successfully.\n","DEBUG:jieba:Prefix dict has been built successfully.\n"]},{"output_type":"stream","name":"stdout","text":["中文斷詞（有標點）： ['我', '喜歡', '跑步', '，', '你', '呢', '？']\n","中文斷詞（無標點）： ['我', '喜歡', '跑步', '你', '呢']\n","中文斷詞（更精簡）： ['喜歡', '跑步']\n"]}]},{"cell_type":"markdown","source":["# Text Digitalize"],"metadata":{"id":"D9kP9X5JepGU"}},{"cell_type":"code","source":["# Create a Tokenizer object\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","\n","tk = Tokenizer(\n","        num_words=None,\n","        filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~\\t\\n',\n","        lower=True,\n","        split=' ',\n","        char_level=False,\n","        oov_token='NiD'\n","    )"],"metadata":{"id":"Tf0cpZPAeid-","executionInfo":{"status":"ok","timestamp":1701757699735,"user_tz":-480,"elapsed":8,"user":{"displayName":"黃茂勛","userId":"15068294769745416772"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Create Mapping by Corpus\n","# 使用語料庫建立字典\n","corpus = [\"I love jogging, and you?\",\n","      \"I love reading!\"]\n","tk.fit_on_texts(corpus)\n","\n","# Show the Mapping Table\n","print(tk.word_index)    # WORD vs. NUMBER\n","print(tk.index_word)    # NUMBER vs. WORD"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q4wZVFieqL2n","executionInfo":{"status":"ok","timestamp":1701757699735,"user_tz":-480,"elapsed":7,"user":{"displayName":"黃茂勛","userId":"15068294769745416772"}},"outputId":"a3c4979a-53c9-4aa2-b15e-8500bd01673b"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["{'NiD': 1, 'i': 2, 'love': 3, 'jogging': 4, 'and': 5, 'you': 6, 'reading': 7}\n","{1: 'NiD', 2: 'i', 3: 'love', 4: 'jogging', 5: 'and', 6: 'you', 7: 'reading'}\n"]}]},{"cell_type":"code","source":["# Test for Mapping Text into Sequence\n","input_text = [\"I love jogging!\",\n","        \"and I love reading, too!\"]\n","\n","seq = tk.texts_to_sequences(input_text)\n","print(seq)\n","\n","# Test for Mapping Sequence into Text\n","text = tk.sequences_to_texts(seq)\n","print(text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YttU_GznqSo-","executionInfo":{"status":"ok","timestamp":1701757699735,"user_tz":-480,"elapsed":4,"user":{"displayName":"黃茂勛","userId":"15068294769745416772"}},"outputId":"07966ee0-9a8d-4961-92cc-7c1d7815f97a"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["[[2, 3, 4], [5, 2, 3, 7, 1]]\n","['i love jogging', 'and i love reading NiD']\n"]}]},{"cell_type":"markdown","source":["# Sequence Alignment"],"metadata":{"id":"ovCd6tOxs9Ku"}},{"cell_type":"code","source":["# Create a Sequence Padding Object\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","padded_seq = pad_sequences(\n","        sequences=seq,\n","        maxlen=5,\n","        dtype=\"int32\",\n","        padding=\"pre\", # pad the front\n","        truncating=\"post\", # truncate the tail\n","        value=0\n","    )\n","\n","print(padded_seq)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xmc6dVXkqX_Z","executionInfo":{"status":"ok","timestamp":1701758412728,"user_tz":-480,"elapsed":4,"user":{"displayName":"黃茂勛","userId":"15068294769745416772"}},"outputId":"8f0804a7-8e02-4c1c-eb1b-bd876d43dc68"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0 0 2 3 4]\n"," [5 2 3 7 1]]\n"]}]},{"cell_type":"markdown","source":["# Encoding"],"metadata":{"id":"F615C_jQs_52"}},{"cell_type":"code","source":["# One-Hot Encoding\n","from tensorflow.keras.utils import to_categorical\n","\n","print(\"獨熱編碼 -------------\")\n","print(to_categorical(padded_seq))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cBepVNRytAhz","executionInfo":{"status":"ok","timestamp":1701759786213,"user_tz":-480,"elapsed":2,"user":{"displayName":"黃茂勛","userId":"15068294769745416772"}},"outputId":"25e6d796-a921-4043-eeea-2250463303b1"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["獨熱編碼 -------------\n","[[[1. 0. 0. 0. 0. 0. 0. 0.]\n","  [1. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 1. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 1. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 1. 0. 0. 0.]]\n","\n"," [[0. 0. 0. 0. 0. 1. 0. 0.]\n","  [0. 0. 1. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 1. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 1.]\n","  [0. 1. 0. 0. 0. 0. 0. 0.]]]\n"]}]},{"cell_type":"code","source":["# Multi-Hot Encoding\n","print(\"多熱編碼 -------------\")\n","print(tk.texts_to_matrix(input_text))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QvV4-p5QyYw9","executionInfo":{"status":"ok","timestamp":1701759798614,"user_tz":-480,"elapsed":2,"user":{"displayName":"黃茂勛","userId":"15068294769745416772"}},"outputId":"e2e87591-b670-408d-e596-631f2797b9f5"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["多熱編碼 -------------\n","[[0. 0. 1. 1. 1. 0. 0. 0.]\n"," [0. 1. 1. 1. 0. 1. 0. 1.]]\n"]}]},{"cell_type":"code","source":["# Word Embedding\n","import tensorflow as tf\n","from tensorflow.keras import layers\n","\n","emb = layers.Embedding(8, 3)\n","\n","# tf.constant(): Convert immediate values into tensor\n","result = emb(tf.constant(padded_seq))\n","print(\"詞向量嵌入 -------------\")\n","print(result.numpy())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hLiAFhqKyY-N","executionInfo":{"status":"ok","timestamp":1701759826533,"user_tz":-480,"elapsed":3058,"user":{"displayName":"黃茂勛","userId":"15068294769745416772"}},"outputId":"674473aa-39bc-482a-fb75-b18b7ccaa379"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["詞向量嵌入 -------------\n","[[[-0.04549634  0.04842453 -0.01803239]\n","  [-0.04549634  0.04842453 -0.01803239]\n","  [-0.02587713  0.00374747  0.01315535]\n","  [ 0.03545367 -0.01526957 -0.01657917]\n","  [ 0.01964043 -0.0327925   0.04979056]]\n","\n"," [[ 0.04811317 -0.03244107 -0.04246626]\n","  [-0.02587713  0.00374747  0.01315535]\n","  [ 0.03545367 -0.01526957 -0.01657917]\n","  [-0.01841354 -0.03726889 -0.04098666]\n","  [ 0.03419845  0.01358436 -0.0463225 ]]]\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"A1MQw6Eqyiq1"},"execution_count":null,"outputs":[]}]}